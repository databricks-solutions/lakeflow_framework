{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee353e42-ff58-4955-9608-12865bd0950e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Run 2 Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./initialize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bca260b-13d1-448f-8082-30b60a85c9ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"INSERT INTO TABLE {staging_schema}.customer (\n",
    "  CUSTOMER_ID,\n",
    "  FIRST_NAME,\n",
    "  LAST_NAME,\n",
    "  EMAIL,\n",
    "  DELETE_FLAG,\n",
    "  LOAD_TIMESTAMP)\n",
    "VALUES\n",
    "  (1, 'John', 'Doe', 'jdoe@example.com', NULL, '2023-01-02 10:00:00')\n",
    "  , (3, 'Alice', 'Green', 'alice.green@example.com', NULL, '2023-01-02 10:00:00')\n",
    "  , (4, 'Joe', 'Bloggs', 'joe.bloggs@example.com', NULL, '2023-01-02 10:00:00')\n",
    "  , (10, 'Richard', 'Johnson', 'richard.johnson@example.com', True, '2023-01-02 10:00:00');\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"INSERT OVERWRITE TABLE {staging_schema}.customer_snapshot_source (\n",
    "  CUSTOMER_ID,\n",
    "  FIRST_NAME,\n",
    "  LAST_NAME,\n",
    "  EMAIL,\n",
    "  DELETE_FLAG,\n",
    "  LOAD_TIMESTAMP)\n",
    "VALUES\n",
    "  (1, 'John', 'Doe', 'jdoe@example.com', NULL, '2023-01-02 10:00:00')\n",
    "  , (2, 'Jane', 'Smith', 'jane.smith@example.com', NULL, '2023-01-01 10:00:00')\n",
    "  , (3, 'Alice', 'Green', 'alice.green@example.com', NULL, '2023-01-02 10:00:00')\n",
    "  , (4, 'Joe', 'Bloggs', 'joe.bloggs@example.com', NULL, '2023-01-02 10:00:00')\n",
    "  , (10, 'Richard', 'Johnson', 'richard.johnson@example.com', NULL, '2023-01-01 10:00:00')\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"INSERT INTO TABLE {staging_schema}.customer_address (\n",
    "  CUSTOMER_ID,\n",
    "  CITY,\n",
    "  STATE,\n",
    "  LOAD_TIMESTAMP)\n",
    "VALUES\n",
    "  (2, 'Perth', 'WA', '2023-01-02 10:00:00')\n",
    "  , (3, 'Sydney', 'NSW', '2023-01-02 10:00:00')\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"INSERT INTO TABLE {staging_schema}.customer_historical_snapshot_source (\n",
    "  CUSTOMER_ID,\n",
    "  FIRST_NAME,\n",
    "  LAST_NAME,\n",
    "  EMAIL,\n",
    "  LOAD_TIMESTAMP)\n",
    "VALUES\n",
    "  (6, 'Someone', 'else', 'someone.else@example.com', '2024-04-01 10:00:00')\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_content = \"\"\"CUSTOMER_ID,FIRST_NAME,LAST_NAME,EMAIL,DELETE_FLAG,LOAD_TIMESTAMP\\n\n",
    "6,Someone,else,someone.else@example.com,,2023-03-01 10:00:00\\n\n",
    "\"\"\"\n",
    "\n",
    "dbutils.fs.put(\n",
    "  f\"{customer_snapshot_file_path}/customer_2024_03_01.csv\",\n",
    "  file_content,\n",
    "  True)\n",
    "\n",
    "dbutils.fs.put(\n",
    "  f\"{customer_snapshot_partitioned_file_path}/YEAR=2024/MONTH=03/DAY=01/customer.csv\",\n",
    "  file_content,\n",
    "  True)\n",
    "\n",
    "dbutils.fs.put(\n",
    "  f\"{template_samples_customer_file_path}/customer_2024_03_01.csv\",\n",
    "  file_content,\n",
    "  True)\n",
    "\n",
    "# Template samples customer_address data for run 2\n",
    "customer_address_file_content = \"\"\"CUSTOMER_ID,CITY,STATE,LOAD_TIMESTAMP\n",
    "2,Perth,WA,2024-03-01 10:00:00\n",
    "3,Sydney,NSW,2024-03-01 10:00:00\n",
    "6,Adelaide,SA,2024-03-01 10:00:00\n",
    "\"\"\"\n",
    "\n",
    "dbutils.fs.put(\n",
    "  f\"{template_samples_customer_address_file_path}/customer_address_2024_03_01.csv\",\n",
    "  customer_address_file_content,\n",
    "  True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"CUSTOMER_ID\", StringType(), True),\n",
    "    StructField(\"FIRST_NAME\", StringType(), True),\n",
    "    StructField(\"LAST_NAME\", StringType(), True),\n",
    "    StructField(\"EMAIL\", StringType(), True),\n",
    "    StructField(\"DELETE_FLAG\", StringType(), True),\n",
    "    StructField(\"LOAD_TIMESTAMP\", StringType(), True)\n",
    "])\n",
    "\n",
    "data = [\n",
    "    [\"6\", \"Someone\", \"else\", \"someone.else@example.com\", \"\", \"2023-03-01 10:00:00\"]\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "df.write.parquet(\n",
    "    f\"{customer_snapshot_partitioned_parquet_file_path}/YEAR=2024/MONTH=03/DAY=01/customer.parquet\",\n",
    "    mode=\"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_content = \"\"\"CUSTOMER_ID,FIRST_NAME,LAST_NAME,EMAIL,DELETE_FLAG,LOAD_TIMESTAMP\\n\n",
    "1,John,Doe,jdoe@example.com,,2023-01-02 10:00:00\\n\n",
    "3,Alice,Green,alice.green@example.com,,2023-01-02 10:00:00\\n\n",
    "4,Joe,Bloggs,joe.bloggs@example.com,,2023-01-02 10:00:00\\n\n",
    "\"\"\"\n",
    "\n",
    "dbutils.fs.put(\n",
    "  f\"{customer_file_path}/customer_2.csv\",\n",
    "  file_content,\n",
    "  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"INSERT INTO TABLE {staging_schema}.customer_snapshots (\n",
    "  CUSTOMER_ID,\n",
    "  FIRST_NAME,\n",
    "  LAST_NAME,\n",
    "  EMAIL,\n",
    "  UPDATE_TIMESTAMP,\n",
    "  SNAPSHOT_TIMESTAMP,\n",
    "  SNAPSHOT_VERSION)\n",
    "VALUES\n",
    "  (1, 'John', 'Doe', 'jdoe@example.com', '2023-01-02 00:00:00','2023-01-03T00:00:00', 2)\n",
    "  , (3, 'Alice', 'Green', 'alice.green@example.com', '2023-01-02 00:00:00', '2023-01-03T00:00:00', 2)\n",
    "  , (4, 'Joe', 'Bloggs', 'j.bloggs@example.com', '2023-01-03 00:00:00', '2023-01-03T00:00:00', 2) \n",
    "  \"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "notebook",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
