{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee353e42-ff58-4955-9608-12865bd0950e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Create Schemas and Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./initialize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {staging_schema}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {bronze_schema}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {bronze_schema}_yaml\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {silver_schema}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {gold_schema}\")\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {staging_schema}.{staging_volume}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {dpm_schema}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"DROP TABLE IF EXISTS {staging_schema}.customer\")\n",
    "spark.sql(f\"\"\"CREATE TABLE {staging_schema}.customer (\n",
    "  CUSTOMER_ID integer,\n",
    "  FIRST_NAME string,\n",
    "  LAST_NAME string,\n",
    "  EMAIL string,\n",
    "  DELETE_FLAG boolean,\n",
    "  LOAD_TIMESTAMP timestamp)\n",
    "TBLPROPERTIES (delta.enableChangeDataFeed = true);\"\"\")\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {staging_schema}.customer_address\")\n",
    "spark.sql(f\"\"\"CREATE TABLE {staging_schema}.customer_address (\n",
    "  CUSTOMER_ID integer,\n",
    "  CITY string,\n",
    "  STATE string,\n",
    "  LOAD_TIMESTAMP timestamp)\n",
    "TBLPROPERTIES (delta.enableChangeDataFeed = true);\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"DROP TABLE IF EXISTS {staging_schema}.customer_snapshot_source\")\n",
    "spark.sql(f\"\"\"CREATE TABLE {staging_schema}.customer_snapshot_source (\n",
    "  CUSTOMER_ID integer,\n",
    "  FIRST_NAME string,\n",
    "  LAST_NAME string,\n",
    "  EMAIL string,\n",
    "  DELETE_FLAG boolean,\n",
    "  LOAD_TIMESTAMP timestamp)\n",
    "TBLPROPERTIES (delta.enableChangeDataFeed = true);\"\"\")\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {staging_schema}.customer_historical_snapshot_source\")\n",
    "spark.sql(f\"\"\"CREATE TABLE {staging_schema}.customer_historical_snapshot_source (\n",
    "  CUSTOMER_ID integer,\n",
    "  FIRST_NAME string,\n",
    "  LAST_NAME string,\n",
    "  EMAIL string,\n",
    "  LOAD_TIMESTAMP timestamp)\n",
    "TBLPROPERTIES (delta.enableChangeDataFeed = true);\"\"\")\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {staging_schema}.customer_snapshots\")\n",
    "spark.sql(f\"\"\"CREATE TABLE {staging_schema}.customer_snapshots (\n",
    "  CUSTOMER_ID integer,\n",
    "  FIRST_NAME string,\n",
    "  LAST_NAME string,\n",
    "  EMAIL string,\n",
    "  UPDATE_TIMESTAMP timestamp,\n",
    "  SNAPSHOT_TIMESTAMP timestamp,\n",
    "  SNAPSHOT_VERSION integer)\n",
    "TBLPROPERTIES (delta.enableChangeDataFeed = true);\"\"\")\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {staging_schema}.customer_purchase\")\n",
    "spark.sql(f\"\"\"CREATE TABLE {staging_schema}.customer_purchase (\n",
    "  CUSTOMER_ID integer,\n",
    "  PRODUCT string,\n",
    "  QUANTITY integer,\n",
    "  PRICE decimal(10, 2),\n",
    "  PURCHASE_TIMESTAMP timestamp)\n",
    "TBLPROPERTIES (delta.enableChangeDataFeed = true);\"\"\")\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {bronze_schema}.table_to_migrate_scd0\")\n",
    "spark.sql(f\"\"\"CREATE TABLE {bronze_schema}.table_to_migrate_scd0 (  \n",
    "  CUSTOMER_ID integer,\n",
    "  FIRST_NAME string,\n",
    "  LAST_NAME string,\n",
    "  EMAIL string\n",
    ") TBLPROPERTIES (delta.enableChangeDataFeed = true);\"\"\")\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {bronze_schema}.table_to_migrate_scd2\")\n",
    "spark.sql(f\"\"\"CREATE TABLE {bronze_schema}.table_to_migrate_scd2 (\n",
    "  CUSTOMER_ID integer,\n",
    "  FIRST_NAME string,\n",
    "  LAST_NAME string,\n",
    "  EMAIL string,\n",
    "  EFFECTIVE_FROM timestamp,\n",
    "  EFFECTIVE_TO timestamp)\n",
    "TBLPROPERTIES (delta.enableChangeDataFeed = true);\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"DROP TABLE IF EXISTS {staging_schema}.kafka_sink_sample_source\")\n",
    "spark.sql(f\"\"\"CREATE TABLE {staging_schema}.kafka_sink_sample_source (\n",
    "    Message_Id BIGINT GENERATED BY DEFAULT AS IDENTITY (START WITH 1 INCREMENT BY 1),\n",
    "    Message_Ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    Message_payload STRING\n",
    ")\n",
    "USING delta\n",
    "TBLPROPERTIES (\n",
    "    'delta.enableChangeDataFeed' = 'true',\n",
    "    'delta.feature.allowColumnDefaults' = 'supported',\n",
    "    'delta.feature.changeDataFeed' = 'supported',\n",
    "    'delta.feature.columnMapping' = 'supported',\n",
    "    'delta.feature.generatedColumns' = 'supported',\n",
    "    'delta.feature.invariants' = 'supported',\n",
    "    'delta.minReaderVersion' = '3',\n",
    "    'delta.minWriterVersion' = '7'\n",
    ")\"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "notebook",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
